# Overview
CUDA_MINIMAL_FLASH_ATTENTION is a minimal CUDA library for flash attention inference.

